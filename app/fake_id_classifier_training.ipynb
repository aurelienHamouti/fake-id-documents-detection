{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3411e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os, torchvision, torch, glob, pathlib\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a36cad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for calculator device\n",
    "calculatorDevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e470c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(calculatorDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e15da2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms input data for processing\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((500, 500)),\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize([0.5,0.5,0.5], \n",
    "                        [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b692618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loader\n",
    "\n",
    "#Path for training and testing data directory\n",
    "trainingPath='data/id-fr-documents-zone-4/training_set'\n",
    "testPath='data/id-fr-documents-zone-4/test_set'\n",
    "\n",
    "trainingLoader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(trainingPath,transform=transformer),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "testLoader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(testPath,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f58dbca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['authentics', 'counterfeits']\n"
     ]
    }
   ],
   "source": [
    "# categories (classes) extraction\n",
    "root=pathlib.Path(trainingPath)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f025ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional neuronal network (CNN) definition\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=6):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #initial input shape= (256,3,150,150)\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #new shape= (256,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        self.relu1=nn.ReLU()     \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #new shape= (256,12,75,75)\n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #new shape= (256,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #new shape= (256,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        self.relu3=nn.ReLU()\n",
    "        self.fc=nn.Linear(in_features=250 * 250 * 32,out_features=num_classes)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)  \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output) \n",
    "            \n",
    "        #Output shape like the last input shape (256,32,75,75)     \n",
    "        output=output.view(-1,32*250*250)\n",
    "                \n",
    "        output=self.fc(output) \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "19854a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierModel=ConvNet(num_classes=6).to(calculatorDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90a23b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optmizer and loss function\n",
    "optimizer=Adam(classifierModel.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "lossFunction=nn.CrossEntropyLoss()\n",
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a0cdaefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the size of training and testing images, .png images in input\n",
    "trainingCount=len(glob.glob(trainingPath+'/**/*.png'))\n",
    "testCount=len(glob.glob(testPath+'/**/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04bbe789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 7\n"
     ]
    }
   ],
   "source": [
    "print(trainingCount,testCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "785557f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(1.9917) Train Accuracy: 0.0 Test Accuracy: 0.5714285714285714\n",
      "Epoch: 1 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.5714285714285714\n",
      "Epoch: 2 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.5714285714285714\n",
      "Epoch: 3 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.5714285714285714\n",
      "Epoch: 4 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.5714285714285714\n",
      "Epoch: 5 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.5714285714285714\n",
      "Epoch: 6 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.7142857142857143\n",
      "Epoch: 7 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.7142857142857143\n",
      "Epoch: 8 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.8571428571428571\n",
      "Epoch: 9 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Training and saving best performant model\n",
    "\n",
    "bestAccuracy=0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    classifierModel.train()\n",
    "    trainAccuracy=0.0\n",
    "    trainLoss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(trainingLoader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=classifierModel(images)\n",
    "        loss=lossFunction(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        trainLoss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        trainAccuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    trainAccuracy=trainAccuracy/trainingCount\n",
    "    trainLoss=trainLoss/trainingCount\n",
    "    \n",
    "    \n",
    "    # Evaluation on testing dataset\n",
    "    classifierModel.eval()\n",
    "    \n",
    "    testAccuracy=0.0\n",
    "    for i, (images,labels) in enumerate(testLoader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        outputs=classifierModel(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        testAccuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    testAccuracy=testAccuracy/testCount\n",
    "    \n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(trainLoss)+' Train Accuracy: '+str(trainAccuracy)+' Test Accuracy: '+str(testAccuracy))\n",
    "    \n",
    "    #Save the best model\n",
    "    if testAccuracy>bestAccuracy:\n",
    "        torch.save(classifierModel.state_dict(),'fake_ID_FR_zone_4_classifier.model') #Check the name according data input\n",
    "        bestAccuracy=testAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adafcf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
